{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4667f501-a4b8-4cca-9d9f-bf1952f02679",
   "metadata": {},
   "source": [
    "# Pretraining for ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc6a5cba-6b34-4cd4-9e89-14bddb529b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T14:27:05.515747Z",
     "iopub.status.busy": "2025-03-22T14:27:05.514586Z",
     "iopub.status.idle": "2025-03-22T14:27:10.279047Z",
     "shell.execute_reply": "2025-03-22T14:27:10.278240Z",
     "shell.execute_reply.started": "2025-03-22T14:27:05.515708Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.31.0)\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
      "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.12.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio datasets transformers soundfile jiwer --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install librosa --index-url https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198bcc5c-606e-4ad6-a148-bb915684fb5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:09:21.254469Z",
     "iopub.status.busy": "2025-03-22T13:09:21.253555Z",
     "iopub.status.idle": "2025-03-22T13:09:23.835069Z",
     "shell.execute_reply": "2025-03-22T13:09:23.834224Z",
     "shell.execute_reply.started": "2025-03-22T13:09:21.254431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.29.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.14)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "\u001b[33m  WARNING: The script evaluate-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23424d0d-66db-4a73-accb-4b5e1320a8f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T14:27:28.704297Z",
     "iopub.status.busy": "2025-03-22T14:27:28.703290Z",
     "iopub.status.idle": "2025-03-22T14:27:37.881706Z",
     "shell.execute_reply": "2025-03-22T14:27:37.881131Z",
     "shell.execute_reply.started": "2025-03-22T14:27:28.704260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset, disable_caching\n",
    "import evaluate\n",
    "from transformers import Wav2Vec2ForPreTraining, Wav2Vec2FeatureExtractor, Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import Wav2Vec2Encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fa8ef5-4b17-4faa-a1a9-5435234f3e46",
   "metadata": {},
   "source": [
    "## Finetuning Wav2Vec2 model on CTC loss (5 points)\n",
    "\n",
    "\n",
    "In this task you have to create pipeline for finetuning pretrained multilingual Wav2Vec2 model on belarusian audio from [Fleurs](https://huggingface.co/datasets/google/fleurs) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c568-8567-497b-983c-c38c45642a9f",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8eeaa1-62f5-4ccc-8ace-74b023719835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T14:27:37.883143Z",
     "iopub.status.busy": "2025-03-22T14:27:37.882647Z",
     "iopub.status.idle": "2025-03-22T14:27:42.438768Z",
     "shell.execute_reply": "2025-03-22T14:27:42.438110Z",
     "shell.execute_reply.started": "2025-03-22T14:27:37.883115Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    }
   ],
   "source": [
    "fleurs = load_dataset(\"google/fleurs\", \"be_by\", split=[\"train\", \"validation\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b35708-f6a7-4d98-b26f-da8f70d87997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T14:27:45.476190Z",
     "iopub.status.busy": "2025-03-22T14:27:45.475409Z",
     "iopub.status.idle": "2025-03-22T14:27:45.530040Z",
     "shell.execute_reply": "2025-03-22T14:27:45.529409Z",
     "shell.execute_reply.started": "2025-03-22T14:27:45.476160Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'вышыня двух пілонаў складае 83 метры даўжыня моста - 378 метраў праезная частка складаецца з дзвюх палос шырыня кожнай - 3,50 м'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fleurs[0][\"transcription\"][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22657fca-bf70-465b-b51d-d7dec36a6d3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T14:27:45.877343Z",
     "iopub.status.busy": "2025-03-22T14:27:45.876508Z",
     "iopub.status.idle": "2025-03-22T14:28:04.192418Z",
     "shell.execute_reply": "2025-03-22T14:28:04.191804Z",
     "shell.execute_reply.started": "2025-03-22T14:27:45.877315Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 396,\n",
       " 'num_samples': 250560,\n",
       " 'path': '/home/jupyter/datasphere/project/datasetscache/downloads/extracted/8cd4c5385f61a5730e851ddf4922754fd4553bead0ae50d2a9971f28962d3414/10009414287632395082.wav',\n",
       " 'audio': {'path': 'train/10009414287632395082.wav',\n",
       "  'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00031281,\n",
       "         -0.00038069, -0.00132966]),\n",
       "  'sampling_rate': 16000},\n",
       " 'transcription': 'у той жа час паблізу ад верагодных маршрутаў уварвання базіравалася вельмі мала караблёў каралеўскага флоту таму што адміралы асцерагаліся іх патаплення нямецкімі паветранымі сіламі',\n",
       " 'raw_transcription': 'У той жа час паблізу ад верагодных маршрутаў уварвання базіравалася вельмі мала караблёў каралеўскага флоту, таму што адміралы асцерагаліся іх патаплення нямецкімі паветранымі сіламі.',\n",
       " 'gender': 1,\n",
       " 'lang_id': 6,\n",
       " 'language': 'Belarusian',\n",
       " 'lang_group_id': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fleurs[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd9aaf9-a7e8-460f-a51b-611f2bd7aaf2",
   "metadata": {},
   "source": [
    "In this task, you should:\n",
    "\n",
    "* filter all samples, where `transcription` includes digits. Hint: take care of specific belarussian symbols \"і\", \"ў\";\n",
    "* remove punctuation from `transcription`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0c6124e-0f9f-46f5-9354-034aafee3e26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T14:28:04.194608Z",
     "iopub.status.busy": "2025-03-22T14:28:04.193463Z",
     "iopub.status.idle": "2025-03-22T14:28:04.206535Z",
     "shell.execute_reply": "2025-03-22T14:28:04.205953Z",
     "shell.execute_reply.started": "2025-03-22T14:28:04.194571Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def is_not_contain_digits(sample):\n",
    "    return not bool(re.search(r'[\\d]', sample))\n",
    "\n",
    "print(is_not_contain_digits(\"вышыня двух пілонаў складае метры даўжыня моста -  метраў праезная частка складаецца з дзвюх палос шырыня кожнай -  м\"))\n",
    "print(is_not_contain_digits(\"вышыня двух пілонаў складае 83 метры даўжыня моста - 378 метраў праезная частка складаецца з дзвюх палос шырыня кожнай - 3,50 м\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0885ae69-577e-4d72-bcc1-4e5301971582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T14:28:04.208222Z",
     "iopub.status.busy": "2025-03-22T14:28:04.207242Z",
     "iopub.status.idle": "2025-03-22T14:28:04.226118Z",
     "shell.execute_reply": "2025-03-22T14:28:04.225619Z",
     "shell.execute_reply.started": "2025-03-22T14:28:04.208193Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вышыня двух пілонаў складае 83 метры даўжыня моста  378 метраў праезная частка складаецца з дзвюх палос шырыня кожнай\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(sample):\n",
    "        sample = sample.translate(str.maketrans('', '', string.punctuation))\n",
    "        return sample\n",
    "    \n",
    "print(remove_punctuation(\"вышыня двух, пілонаў складае 83 метры даўжыня моста - 378 метраў праезная частка складаецца, з дзвюх палос шырыня кожнай\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7edc1319-a5e0-4631-9557-f3f20da87791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T14:28:04.228447Z",
     "iopub.status.busy": "2025-03-22T14:28:04.227493Z",
     "iopub.status.idle": "2025-03-22T14:28:04.245847Z",
     "shell.execute_reply": "2025-03-22T14:28:04.245237Z",
     "shell.execute_reply.started": "2025-03-22T14:28:04.228421Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_not_contain_digits(sample):\n",
    "    return not bool(re.search(r'[\\d]', sample[\"transcription\"]))\n",
    "\n",
    "def remove_punctuation(sample):\n",
    "        sample[\"transcription\"] = sample[\"transcription\"].translate(str.maketrans('', '', string.punctuation))\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2df4169-4fce-48f0-881d-ff366ee20077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T14:28:04.247588Z",
     "iopub.status.busy": "2025-03-22T14:28:04.246622Z",
     "iopub.status.idle": "2025-03-22T14:28:04.282201Z",
     "shell.execute_reply": "2025-03-22T14:28:04.281615Z",
     "shell.execute_reply.started": "2025-03-22T14:28:04.247557Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fleurs[0] = fleurs[0].filter(is_not_contain_digits)\n",
    "fleurs[0] = fleurs[0].map(remove_punctuation)\n",
    "\n",
    "preprocessed_train = fleurs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e7905eb-22b9-4d6b-add4-b8bc99853f95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T14:28:04.283431Z",
     "iopub.status.busy": "2025-03-22T14:28:04.282885Z",
     "iopub.status.idle": "2025-03-22T14:28:04.309110Z",
     "shell.execute_reply": "2025-03-22T14:28:04.308413Z",
     "shell.execute_reply.started": "2025-03-22T14:28:04.283405Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fleurs[1] = fleurs[1].filter(is_not_contain_digits)\n",
    "fleurs[1] = fleurs[1].map(remove_punctuation)\n",
    "\n",
    "preprocessed_val = fleurs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60dd623-c031-4066-b408-4337b67056e9",
   "metadata": {},
   "source": [
    "#### Train tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3bdfb6-91fd-4b3f-b1f4-acb10f122a5b",
   "metadata": {},
   "source": [
    "There you should train your own BPE tokenizer based on texts from Fleurs dataset using [HuggingFace tokenizer](https://huggingface.co/docs/tokenizers/en/training_from_memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42affbc0-7b19-4fb4-ad36-faf51a211ef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:05:14.740497Z",
     "iopub.status.busy": "2025-03-22T15:05:14.739586Z",
     "iopub.status.idle": "2025-03-22T15:05:17.686002Z",
     "shell.execute_reply": "2025-03-22T15:05:17.685387Z",
     "shell.execute_reply.started": "2025-03-22T15:05:14.740466Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import models, trainers, tokenizers, normalizers, pre_tokenizers, decoders\n",
    "\n",
    "PAD_TOKEN = \"[PAD]\"\n",
    "BOS_TOKEN = \"[BOS]\"\n",
    "EOS_TOKEN = \"[EOS]\"\n",
    "UNK_TOKEN = \"[UNK]\"\n",
    "VOCAB_SIZE = 1000\n",
    "\n",
    "tokenizer = tokenizers.Tokenizer(models.BPE(unk_token=UNK_TOKEN))\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.WhitespaceSplit()\n",
    "tokenizer.normalizer = normalizers.Sequence([normalizers.NFD(), normalizers.Lowercase(), normalizers.StripAccents()])\n",
    "tokenizer.decoder = decoders.BPEDecoder()\n",
    "\n",
    "all_text = [sample['transcription'] for sample in preprocessed_train]\n",
    "\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    special_tokens=[PAD_TOKEN, BOS_TOKEN, EOS_TOKEN, UNK_TOKEN]\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(all_text, trainer)\n",
    "tokenizer.save(\"fleurs_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bc17297-7df2-4a71-8de2-dd4a6fc9a3cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:05:20.582135Z",
     "iopub.status.busy": "2025-03-22T15:05:20.581320Z",
     "iopub.status.idle": "2025-03-22T15:05:20.596741Z",
     "shell.execute_reply": "2025-03-22T15:05:20.596154Z",
     "shell.execute_reply.started": "2025-03-22T15:05:20.582102Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'у той жа час паблізу ад верагодных маршрутаў уварвання базіравалася вельмі мала караблёў каралеўскага флоту таму што адміралы асцерагаліся іх патаплення нямецкімі паветранымі сіламі'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train[0]['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5449b5ac-7fce-4c93-9368-133702685335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:05:21.081371Z",
     "iopub.status.busy": "2025-03-22T15:05:21.080558Z",
     "iopub.status.idle": "2025-03-22T15:05:21.092664Z",
     "shell.execute_reply": "2025-03-22T15:05:21.092110Z",
     "shell.execute_reply.started": "2025-03-22T15:05:21.081337Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'утоижачаспаблізуадверагодныхмаршрутаууварваннябазіраваласявельмімалакараблеукаралеускагафлотутамуштоадміралыасцерагалісяіхпатапленнянямецкіміпаветранымісіламі'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(preprocessed_train[0]['transcription']).ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bee0f1-e988-477f-b608-56a5afba8f0d",
   "metadata": {},
   "source": [
    "#### Loading model and preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9feb4b5b-8b94-4114-ab60-600bf50c69b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:05:21.878228Z",
     "iopub.status.busy": "2025-03-22T15:05:21.877345Z",
     "iopub.status.idle": "2025-03-22T15:05:34.622018Z",
     "shell.execute_reply": "2025-03-22T15:05:34.621353Z",
     "shell.execute_reply.started": "2025-03-22T15:05:21.878203Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-xls-r-300m and are newly initialized: ['lm_head.weight', 'lm_head.bias', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\n",
    "   \"facebook/wav2vec2-xls-r-300m\"\n",
    ")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-xls-r-300m\", \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=tokenizer.token_to_id(PAD_TOKEN),\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc5bac96-0183-4e64-be12-e0d23315e852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:05:34.623666Z",
     "iopub.status.busy": "2025-03-22T15:05:34.623228Z",
     "iopub.status.idle": "2025-03-22T15:05:34.639122Z",
     "shell.execute_reply": "2025-03-22T15:05:34.638563Z",
     "shell.execute_reply.started": "2025-03-22T15:05:34.623644Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': [array([ 0.0002121 ,  0.0002121 ,  0.0002121 , ..., -0.00907149,\n",
       "       -0.01108636, -0.03925026], dtype=float32)], 'attention_mask': [array([1, 1, 1, ..., 1, 1, 1], dtype=int32)]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor(preprocessed_train[0][\"audio\"][\"array\"], sampling_rate=preprocessed_train[0][\"audio\"][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d04550-d56a-4496-9a48-ea5164233fc5",
   "metadata": {},
   "source": [
    "#### Data processor and data collator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b0be5db-079f-4589-9c21-80cdb9a94afa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:05:34.640156Z",
     "iopub.status.busy": "2025-03-22T15:05:34.639794Z",
     "iopub.status.idle": "2025-03-22T15:05:34.653890Z",
     "shell.execute_reply": "2025-03-22T15:05:34.653291Z",
     "shell.execute_reply.started": "2025-03-22T15:05:34.640133Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CtcDataProcessor:\n",
    "    def __init__(self, tokenizer, feature_extractor):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def __call__(self, row):\n",
    "        \"\"\"\n",
    "            Function applies tokenizer on row['transcription'] and applies feature extractor on audio column in row.\n",
    "            Input: dict with transcription and audio fields\n",
    "            Output: original dict includes `labels` column with tokenized sequence and `input_values` column with computed spectrogram.\n",
    "        \"\"\"\n",
    "        labels = self.tokenizer.encode(row[\"transcription\"]).ids\n",
    "        input_values = self.feature_extractor(row[\"audio\"][\"array\"], sampling_rate=row[\"audio\"][\"sampling_rate\"]).input_values[0]\n",
    "        \n",
    "        return {\"input_values\": input_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f42e7d4-e719-411b-bbfb-8eb9d4fb7ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:05:34.655663Z",
     "iopub.status.busy": "2025-03-22T15:05:34.655128Z",
     "iopub.status.idle": "2025-03-22T15:05:44.680667Z",
     "shell.execute_reply": "2025-03-22T15:05:44.680033Z",
     "shell.execute_reply.started": "2025-03-22T15:05:34.655641Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Map:   0%|          | 0/1927 [00:00<?, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   2%|▏         | 43/1927 [00:00<00:04, 408.49 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   5%|▍         | 87/1927 [00:00<00:04, 416.25 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:   8%|▊         | 148/1927 [00:00<00:04, 406.20 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  10%|▉         | 189/1927 [00:00<00:04, 404.75 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  12%|█▏        | 235/1927 [00:00<00:04, 422.31 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  15%|█▌        | 298/1927 [00:00<00:03, 417.30 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  18%|█▊        | 341/1927 [00:00<00:03, 417.40 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  21%|██        | 404/1927 [00:00<00:03, 415.87 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  23%|██▎       | 448/1927 [00:01<00:03, 419.10 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  26%|██▋       | 510/1927 [00:01<00:03, 412.48 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  29%|██▉       | 556/1927 [00:01<00:03, 422.78 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  32%|███▏      | 619/1927 [00:01<00:03, 419.72 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  34%|███▍      | 663/1927 [00:01<00:02, 422.61 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  38%|███▊      | 726/1927 [00:01<00:02, 417.39 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  41%|████      | 788/1927 [00:01<00:02, 412.93 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  44%|████▍     | 847/1927 [00:02<00:02, 404.52 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  46%|████▌     | 889/1927 [00:02<00:02, 406.46 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  48%|████▊     | 930/1927 [00:02<00:02, 404.09 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  51%|█████▏    | 991/1927 [00:02<00:02, 403.10 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  54%|█████▍    | 1043/1927 [00:04<00:10, 80.55 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  56%|█████▋    | 1085/1927 [00:04<00:08, 101.30 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  59%|█████▉    | 1134/1927 [00:04<00:05, 132.34 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  61%|██████    | 1180/1927 [00:04<00:04, 165.45 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  63%|██████▎   | 1223/1927 [00:04<00:03, 198.46 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  66%|██████▌   | 1267/1927 [00:04<00:02, 233.53 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  68%|██████▊   | 1308/1927 [00:04<00:02, 264.40 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  70%|███████   | 1350/1927 [00:04<00:01, 294.63 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  72%|███████▏  | 1391/1927 [00:05<00:01, 318.86 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  74%|███████▍  | 1433/1927 [00:05<00:01, 342.10 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  77%|███████▋  | 1475/1927 [00:05<00:01, 358.87 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  79%|███████▉  | 1518/1927 [00:05<00:01, 375.96 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  81%|████████  | 1561/1927 [00:05<00:00, 387.93 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  83%|████████▎ | 1604/1927 [00:05<00:00, 398.09 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  87%|████████▋ | 1668/1927 [00:05<00:00, 403.39 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  90%|████████▉ | 1730/1927 [00:05<00:00, 400.89 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  92%|█████████▏| 1776/1927 [00:06<00:00, 412.28 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  95%|█████████▌| 1838/1927 [00:06<00:00, 408.07 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  98%|█████████▊| 1883/1927 [00:06<00:00, 411.97 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map: 100%|██████████| 1927/1927 [00:08<00:00, 226.66 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Map:   0%|          | 0/355 [00:00<?, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  12%|█▏        | 42/355 [00:00<00:00, 403.79 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  29%|██▉       | 104/355 [00:00<00:00, 402.66 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  41%|████▏     | 147/355 [00:00<00:00, 407.15 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  53%|█████▎    | 189/355 [00:00<00:00, 407.25 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  65%|██████▌   | 232/355 [00:00<00:00, 409.86 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map:  77%|███████▋  | 275/355 [00:00<00:00, 412.13 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Map: 100%|██████████| 355/355 [00:01<00:00, 236.75 examples/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "data_processor = CtcDataProcessor(tokenizer, feature_extractor)\n",
    "train = preprocessed_train.map(data_processor, keep_in_memory=True, remove_columns=preprocessed_train.column_names)\n",
    "val = preprocessed_val.map(data_processor, keep_in_memory=True, remove_columns=preprocessed_val.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f85803bc-055c-4c52-955a-b9787d282530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:05:44.682325Z",
     "iopub.status.busy": "2025-03-22T15:05:44.681465Z",
     "iopub.status.idle": "2025-03-22T15:06:15.154939Z",
     "shell.execute_reply": "2025-03-22T15:06:15.154224Z",
     "shell.execute_reply.started": "2025-03-22T15:05:44.682302Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.00039219140307977796,\n",
       " 0.00039219140307977796,\n",
       " 0.00040110311238095164,\n",
       " 0.0004055589670315385,\n",
       " 0.0004100148507859558,\n",
       " 0.00041447070543654263,\n",
       " 0.00041447070543654263,\n",
       " 0.0004055589670315385,\n",
       " 0.00039219140307977796,\n",
       " 0.0003699121007230133,\n",
       " 0.00034763282747007906,\n",
       " 0.00032089767046272755,\n",
       " 0.00030307425186038017,\n",
       " 0.00028525080415420234,\n",
       " 0.0002897066588047892,\n",
       " 0.00030307425186038017,\n",
       " 0.0003342652344144881,\n",
       " 0.0003743679844774306,\n",
       " 0.0004233824147377163,\n",
       " 0.0004768526996485889,\n",
       " 0.0005169554497115314,\n",
       " 0.0005526022869162261,\n",
       " 0.000557058141566813,\n",
       " 0.0005526022869162261,\n",
       " 0.0005124995950609446,\n",
       " 0.00047239684499800205,\n",
       " 0.00040110311238095164,\n",
       " 0.00034763282747007906,\n",
       " 0.0002718832402024418,\n",
       " 0.00024069222854450345,\n",
       " 0.0001916777837323025,\n",
       " 0.00020504536223597825,\n",
       " 0.00020058949303347617,\n",
       " 0.00026297150179743767,\n",
       " 0.00029416251345537603,\n",
       " 0.00038327969377860427,\n",
       " 0.00043229412403889,\n",
       " 0.0005124995950609446,\n",
       " 0.0005526022869162261,\n",
       " 0.000610528455581516,\n",
       " 0.0006283518741838634,\n",
       " 0.0006060726009309292,\n",
       " 0.0007798510487191379,\n",
       " 0.0005526022869162261,\n",
       " 0.0004100148507859558,\n",
       " 0.0005436905776150525,\n",
       " 0.00041447070543654263,\n",
       " 0.000445661717094481,\n",
       " 0.0007263807929120958,\n",
       " 0.000610528455581516,\n",
       " 0.0010828494559973478,\n",
       " 0.0012521720491349697,\n",
       " 0.0007798510487191379,\n",
       " 0.000695189752150327,\n",
       " 0.0005124995950609446,\n",
       " 0.0007620276301167905,\n",
       " 0.0008422330720350146,\n",
       " 0.0002451480831950903,\n",
       " 0.0005793374730274081,\n",
       " 0.0003966472577303648,\n",
       " 0.0007130131707526743,\n",
       " 3.5722743632504717e-05,\n",
       " -0.0013099464122205973,\n",
       " -0.0010648742318153381,\n",
       " -0.001421342953108251,\n",
       " -0.0016129447612911463,\n",
       " -0.0007485083187930286,\n",
       " -0.00129212299361825,\n",
       " -0.0009623895166441798,\n",
       " 0.0007130131707526743,\n",
       " -0.0018580170581117272,\n",
       " -0.0019025756046175957,\n",
       " -0.0014391663717105985,\n",
       " -0.0020718981977552176,\n",
       " -0.0020763541106134653,\n",
       " -0.0018000908894464374,\n",
       " -0.0020763541106134653,\n",
       " -0.0023214262910187244,\n",
       " -0.001840193523094058,\n",
       " -0.00221448577940464,\n",
       " -0.00211200094781816,\n",
       " -0.00205407477915287,\n",
       " -0.0002405404666205868,\n",
       " -0.0016485917149111629,\n",
       " -0.0018000908894464374,\n",
       " -0.002000604523345828,\n",
       " -0.0019916926976293325,\n",
       " -0.0023169703781604767,\n",
       " -0.0020139720290899277,\n",
       " -9.349714673589915e-05,\n",
       " -0.0018580170581117272,\n",
       " -0.0010247714817523956,\n",
       " -0.001563930418342352,\n",
       " -0.0028204824775457382,\n",
       " -0.0016396800056099892,\n",
       " -6.676199700450525e-05,\n",
       " 6.245789700187743e-05,\n",
       " 0.0002451480831950903,\n",
       " -0.0002806432021316141,\n",
       " -0.0015772979240864515,\n",
       " -0.0017198853893205523,\n",
       " -0.002143191872164607,\n",
       " -0.00022717288811691105,\n",
       " -0.00010240886331303045,\n",
       " -0.0013545050751417875,\n",
       " -0.0015193717554211617,\n",
       " -0.0016084889648482203,\n",
       " -0.00033411348704248667,\n",
       " -0.0013455933658406138,\n",
       " -0.0018446494359523058,\n",
       " -0.0013856959994882345,\n",
       " -0.0013901519123464823,\n",
       " -0.0014124312438070774,\n",
       " -0.0015238276682794094,\n",
       " -0.0013455933658406138,\n",
       " -0.0017377088079228997,\n",
       " -0.001207461697049439,\n",
       " -0.00129212299361825,\n",
       " -0.001421342953108251,\n",
       " -0.0014168870402500033,\n",
       " -0.0011940940748900175,\n",
       " -0.001203005900606513,\n",
       " -0.0017510764300823212,\n",
       " -0.001786723267287016,\n",
       " -0.0016040330519899726,\n",
       " -0.001506004249677062,\n",
       " -0.0017510764300823212,\n",
       " -0.0012965789064764977,\n",
       " -0.0015461068833246827,\n",
       " -0.0016619592206552625,\n",
       " -0.0014168870402500033,\n",
       " -0.0013946077087894082,\n",
       " -0.0017109736800193787,\n",
       " -0.0020763541106134653,\n",
       " -0.0019248549360781908,\n",
       " -0.001973869279026985,\n",
       " -0.0018446494359523058,\n",
       " -0.0015416510868817568,\n",
       " -0.0015015483368188143,\n",
       " -0.0017599881393834949,\n",
       " -0.0013678725808858871,\n",
       " -0.001786723267287016,\n",
       " -0.001399063621647656,\n",
       " -0.0026021453086286783,\n",
       " -0.0016040330519899726,\n",
       " -0.0009356543305329978,\n",
       " -0.0014748132089152932,\n",
       " 0.0006016167462803423,\n",
       " -0.0011584472376853228,\n",
       " -0.00027618734748102725,\n",
       " -0.00027173146372660995,\n",
       " -0.0016664151335135102,\n",
       " -0.0017421647207811475,\n",
       " -0.0003742162080015987,\n",
       " -0.00021380532416515052,\n",
       " -0.0019916926976293325,\n",
       " -0.001229741028510034,\n",
       " -0.0014792690053582191,\n",
       " 4.463446020963602e-05,\n",
       " 0.0005526022869162261,\n",
       " 0.0007620276301167905,\n",
       " 0.0009224385139532387,\n",
       " 0.0008912475313991308,\n",
       " 8.919303945731372e-05,\n",
       " -0.001595121342688799,\n",
       " -0.001813458395190537,\n",
       " -0.001644135802052915,\n",
       " -0.0011183444876223803,\n",
       " -0.001372328493744135,\n",
       " -0.0010515067260712385,\n",
       " -0.0016619592206552625,\n",
       " -0.0014168870402500033,\n",
       " -0.001675326842814684,\n",
       " -0.0016797826392576098,\n",
       " -0.001617400674149394,\n",
       " -0.0014347104588523507,\n",
       " -0.0018491053488105536,\n",
       " -0.0014659014996141195,\n",
       " -0.0029541582334786654,\n",
       " -0.002722453558817506,\n",
       " 0.0006149843102321029,\n",
       " 0.0007352925022132695,\n",
       " -6.230613507796079e-05,\n",
       " -0.0023169703781604767,\n",
       " -0.001038139103911817,\n",
       " -0.0023214262910187244,\n",
       " -0.0014881808310747147,\n",
       " -0.002495204797014594,\n",
       " -0.002615512814372778,\n",
       " -0.001840193523094058,\n",
       " -0.0033462736755609512,\n",
       " -0.0002048936003120616,\n",
       " 0.00027633909485302866,\n",
       " 0.000695189752150327,\n",
       " 3.1266885343939066e-05,\n",
       " 0.0006149843102321029,\n",
       " -0.00032074592309072614,\n",
       " -0.0009178309119306505,\n",
       " 0.0010160115780308843,\n",
       " -7.567371358163655e-05,\n",
       " -0.0012252851156517863,\n",
       " -0.00206744228489697,\n",
       " -0.0008509930339641869,\n",
       " -0.00041431892896071076,\n",
       " -0.000490068516228348,\n",
       " 0.0008912475313991308,\n",
       " 0.0001916777837323025,\n",
       " 0.0005303230136632919,\n",
       " -0.001644135802052915,\n",
       " -8.012956823222339e-05,\n",
       " 0.0004991319729015231,\n",
       " 0.0007575717754662037,\n",
       " 8.987594810605515e-06,\n",
       " -0.001532739377580583,\n",
       " 0.000802130380179733,\n",
       " -0.003110113088041544,\n",
       " -0.0026556155644357204,\n",
       " -0.0030655546579509974,\n",
       " -0.0046473839320242405,\n",
       " -0.0025664984714239836,\n",
       " -0.002089721616357565,\n",
       " -0.004126048646867275,\n",
       " -0.0030610987450927496,\n",
       " -0.0016886943485587835,\n",
       " -0.0019961486104875803,\n",
       " -0.002312514465302229,\n",
       " -0.004562722984701395,\n",
       " -0.0012163734063506126,\n",
       " -0.0011985499877482653,\n",
       " -0.0022679560352116823,\n",
       " 9.364890138385817e-05,\n",
       " -0.0039968290366232395,\n",
       " -0.002976437332108617,\n",
       " 0.0002095012168865651,\n",
       " -0.002254588296636939,\n",
       " -0.00200951611623168,\n",
       " -0.0016396800056099892,\n",
       " -0.0021030891221016645,\n",
       " 0.001024923287332058,\n",
       " 0.0007041014614515007,\n",
       " -0.0003519369347486645,\n",
       " 0.00046348513569682837,\n",
       " -0.0021253684535622597,\n",
       " -4.002684727311134e-05,\n",
       " -9.349714673589915e-05,\n",
       " 0.001826977706514299,\n",
       " 0.0021968139335513115,\n",
       " 0.0016175524797290564,\n",
       " 0.0031904703937470913,\n",
       " 0.003257308155298233,\n",
       " 0.005155504215508699,\n",
       " 0.0016977578634396195,\n",
       " 0.004264332354068756,\n",
       " 0.005752589087933302,\n",
       " 0.002294842852279544,\n",
       " 0.003582585835829377,\n",
       " 0.007151728495955467,\n",
       " 0.00672396644949913,\n",
       " 0.002259196015074849,\n",
       " 0.007459182757884264,\n",
       " 0.008167664520442486,\n",
       " 0.005645648576319218,\n",
       " 0.009437584318220615,\n",
       " 0.00871573481708765,\n",
       " 0.00728094857186079,\n",
       " 0.00862216204404831,\n",
       " 0.010003478266298771,\n",
       " 0.005788235925137997,\n",
       " 0.006866553798317909,\n",
       " 0.005356017965823412,\n",
       " 0.0070848907344043255,\n",
       " 0.00975394994020462,\n",
       " 0.0028473692946135998,\n",
       " 0.006229366175830364,\n",
       " 0.006380865350365639,\n",
       " 0.004905975889414549,\n",
       " 0.006019940599799156,\n",
       " 0.005289179738610983,\n",
       " 0.0031592794694006443,\n",
       " 0.001301186508499086,\n",
       " 0.004103921353816986,\n",
       " 0.0023795042652636766,\n",
       " 0.0037875554990023375,\n",
       " 0.005097577814012766,\n",
       " 0.005088666453957558,\n",
       " 0.005516428500413895,\n",
       " 0.005266900639981031,\n",
       " 0.00800279714167118,\n",
       " 0.006937847472727299,\n",
       " 0.004999549128115177,\n",
       " 0.0029364863876253366,\n",
       " 0.004277699626982212,\n",
       " 0.003484556917101145,\n",
       " 0.004447022452950478,\n",
       " 0.005173327401280403,\n",
       " 0.001047202618792653,\n",
       " 0.0008110420894809067,\n",
       " 0.002597841201350093,\n",
       " 0.0006372635834850371,\n",
       " 0.0012833630898967385,\n",
       " 0.0030657064635306597,\n",
       " 0.0027983549516648054,\n",
       " 0.0022190932650119066,\n",
       " 0.00018276605987921357,\n",
       " 0.0009759088279679418,\n",
       " -0.0014970925403758883,\n",
       " 0.001982932910323143,\n",
       " 0.0019963004160672426,\n",
       " 7.136961357900873e-05,\n",
       " -1.774755583028309e-05,\n",
       " -0.0024283668026328087,\n",
       " -0.00014251159154810011,\n",
       " -0.001042594900354743,\n",
       " -0.0019916926976293325,\n",
       " -0.0004321423766668886,\n",
       " -0.0016575034242123365,\n",
       " -0.0020629866048693657,\n",
       " -0.0026244246400892735,\n",
       " -0.004754324443638325,\n",
       " -0.004010196775197983,\n",
       " -0.004486973397433758,\n",
       " -0.0013589608715847135,\n",
       " -0.0004455099406186491,\n",
       " -0.0019649576861411333,\n",
       " 0.00022286879539024085,\n",
       " 4.909031849820167e-05,\n",
       " -2.665927240741439e-05,\n",
       " 0.0010293790837749839,\n",
       " 0.0010739377466961741,\n",
       " -0.0001246881583938375,\n",
       " 0.0007352925022132695,\n",
       " -0.0008910957840271294,\n",
       " -0.001318858121521771,\n",
       " 0.000610528455581516,\n",
       " 0.0002585156471468508,\n",
       " 0.00030307425186038017,\n",
       " 0.00016939849592745304,\n",
       " 0.0018581687472760677,\n",
       " -0.00282939407043159,\n",
       " 0.0013635684736073017,\n",
       " 0.003087985562160611,\n",
       " -0.002468469552695751,\n",
       " 0.0008110420894809067,\n",
       " -0.0015238276682794094,\n",
       " 0.0002807949495036155,\n",
       " -0.0019961486104875803,\n",
       " -0.006327242590487003,\n",
       " 0.0003342652344144881,\n",
       " 0.0017022137762978673,\n",
       " -0.002147647785022855,\n",
       " -0.0009445660980418324,\n",
       " -0.0011450797319412231,\n",
       " -0.00222785328514874,\n",
       " -0.0015505627961829305,\n",
       " 0.00027633909485302866,\n",
       " 0.0006506312056444585,\n",
       " 0.0002451480831950903,\n",
       " 0.000610528455581516,\n",
       " 0.0006506312056444585,\n",
       " -0.003323994344100356,\n",
       " -0.005324674304574728,\n",
       " -0.0028115706518292427,\n",
       " -0.005338042043149471,\n",
       " -0.0041082254610955715,\n",
       " -0.0042820037342607975,\n",
       " -0.0058905682526528835,\n",
       " -0.004179519135504961,\n",
       " 0.00023178050469141454,\n",
       " -0.004063666798174381,\n",
       " -0.006331698503345251,\n",
       " -0.0044112238101661205,\n",
       " -0.0035066846758127213,\n",
       " -1.774755583028309e-05,\n",
       " 0.0006818221881985664,\n",
       " -0.0009534778073430061,\n",
       " -0.0030610987450927496,\n",
       " -0.000931198475882411,\n",
       " -0.0009000074933283031,\n",
       " -0.0001692467340035364,\n",
       " -0.006759461015462875,\n",
       " -0.0031947745010256767,\n",
       " 0.0015685380203649402,\n",
       " -4.8938563850242645e-05,\n",
       " 0.0008511447813361883,\n",
       " -0.00012023229646729305,\n",
       " 0.0008065862348303199,\n",
       " 0.00031198596116155386,\n",
       " 0.000886791676748544,\n",
       " 0.00016494262672495097,\n",
       " 0.0005971608916297555,\n",
       " 0.0003431769728194922,\n",
       " 0.0004233824147377163,\n",
       " 0.00020058949303347617,\n",
       " 0.0003253535251133144,\n",
       " 0.0004233824147377163,\n",
       " 0.0003520886821206659,\n",
       " 1.3443453099171165e-05,\n",
       " 0.00019613363838288933,\n",
       " 0.0005080437404103577,\n",
       " 0.0003342652344144881,\n",
       " 0.00021395707153715193,\n",
       " 0.0002585156471468508,\n",
       " 0.0003164418158121407,\n",
       " 0.00015603091742377728,\n",
       " 0.000307530106510967,\n",
       " 0.00014711919357068837,\n",
       " 0.0003164418158121407,\n",
       " 0.00019613363838288933,\n",
       " 0.0003387211181689054,\n",
       " 0.00024960393784567714,\n",
       " 0.00023623635934200138,\n",
       " 0.00013375162961892784,\n",
       " 0.00024069222854450345,\n",
       " 0.0002718832402024418,\n",
       " 0.0002273246500408277,\n",
       " 0.00018276605987921357,\n",
       " 7.582546822959557e-05,\n",
       " 8.473718480672687e-05,\n",
       " 0.00012038405111525208,\n",
       " 0.00019613363838288933,\n",
       " 0.00027633909485302866,\n",
       " 0.00026297150179743767,\n",
       " 0.000254059792496264,\n",
       " 0.00027633909485302866,\n",
       " 0.00032089767046272755,\n",
       " 0.00032980937976390123,\n",
       " 0.0003431769728194922,\n",
       " 0.0003520886821206659,\n",
       " 0.00034763282747007906,\n",
       " 0.00036545624607242644,\n",
       " 0.00035654453677125275,\n",
       " 0.0003788238391280174,\n",
       " 0.0003699121007230133,\n",
       " 0.0003788238391280174,\n",
       " 0.0003788238391280174,\n",
       " 0.0003877355484291911,\n",
       " 0.00038327969377860427,\n",
       " 0.0003877355484291911,\n",
       " 0.00038327969377860427,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " 0.0003877355484291911,\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['input_values'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d5e826f-2e25-41e0-be1f-330a2b14a48d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:06:15.156584Z",
     "iopub.status.busy": "2025-03-22T15:06:15.155734Z",
     "iopub.status.idle": "2025-03-22T15:06:15.169645Z",
     "shell.execute_reply": "2025-03-22T15:06:15.169113Z",
     "shell.execute_reply.started": "2025-03-22T15:06:15.156556Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CTCDataCollator:\n",
    "    # HuggingFace requires pad transcript tokens with this value\n",
    "    LABELS_PAD_IDX = -100\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_tokens(tokens_batch, type=torch.float32, pad_value=0.0):\n",
    "        \"\"\"\n",
    "            Function collates list of tokens\n",
    "        \"\"\"\n",
    "        max_len = max(len(tokens) for tokens in tokens_batch)\n",
    "        padded_tokens = [tokens + [pad_value] * (max_len - len(tokens)) for tokens in tokens_batch]\n",
    "\n",
    "        return torch.tensor(padded_tokens)\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        \"\"\"\n",
    "            Function collates `input_values` and `labels` into one tensor respectively\n",
    "            Input: list with dicts, output of CTCDataProcessor\n",
    "            Output row includes `labels` column with tokenized sequence, `input_values` column with computed spectrogram and \n",
    "            `attention_mask` (0 for not-attending position, 1 for attending)\n",
    "        \"\"\"\n",
    "        batch_labels = [item[\"labels\"] for item in batch]\n",
    "        batch_input_values = [item[\"input_values\"] for item in batch]\n",
    "\n",
    "        input_values = self.collate_tokens(batch_input_values, pad_value=0.0)\n",
    "        labels = self.collate_tokens(batch_labels, pad_value=self.LABELS_PAD_IDX)\n",
    "        \n",
    "        attention_mask = []\n",
    "        for val in batch_input_values:\n",
    "            attention_mask.append([1] * len(val) + [0] * (input_values.size(1) - len(val)))\n",
    "        attention_mask = torch.tensor(attention_mask, dtype=torch.long)\n",
    "\n",
    "        return {\"input_values\": input_values, \"labels\": labels, \"attention_mask\": attention_mask}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec64935-37c3-4947-a5d3-22842ca6f6ce",
   "metadata": {},
   "source": [
    "#### Inference and metrics computing\n",
    "\n",
    "There you should use simple greedy straregy for CTC output decoding. \n",
    "\n",
    "Hint: Don't forget about padding value -100 in reference.\n",
    "\n",
    "Hint: Don't forget about CTC output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "669c3a17-2256-4b56-8c2c-1cb0b6ae4439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:06:15.170840Z",
     "iopub.status.busy": "2025-03-22T15:06:15.170331Z",
     "iopub.status.idle": "2025-03-22T15:06:16.099795Z",
     "shell.execute_reply": "2025-03-22T15:06:16.099216Z",
     "shell.execute_reply.started": "2025-03-22T15:06:15.170814Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "class MetricsComputer:\n",
    "    def __call__(self, pred):\n",
    "        \"\"\"\n",
    "            Input: object with fields `predictions` for CTC model output and `label_ids` for tokenized reference;\n",
    "            Output: dict with key `wer` and computed wer\n",
    "        \"\"\"\n",
    "        # model prediction tensor, tensor batch_size x max_seq_len x vocab_size\n",
    "        preds_logits = pred.predictions\n",
    "        # reference, tensor batch_size x max_seq_len\n",
    "        label_ids = pred.label_ids\n",
    "        \n",
    "        pred_ids = torch.argmax(torch.tensor(preds_logits), dim=-1)\n",
    "        \n",
    "        pred_str = []\n",
    "        label_str = []\n",
    "        for pred in pred_ids:\n",
    "            pred_tokens = [int(idx) for idx, _ in groupby(pred.tolist()) if int(idx) != 0]\n",
    "            pred_str.append(tokenizer.decode(pred_tokens))\n",
    "        for label in label_ids:\n",
    "            label_tokens = [int(idx) for idx in label.tolist() if int(idx) != CTCDataCollator.LABELS_PAD_IDX]\n",
    "            label_str.append(tokenizer.decode(label_tokens))\n",
    "    \n",
    "        print(f\"Prediction: {pred_str[0]}\")\n",
    "        print(f\"Reference: {label_str[0]}\")\n",
    "        \n",
    "        wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "        return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1fa62c-b147-4fa7-9b47-77069b7e4fb3",
   "metadata": {},
   "source": [
    "#### Overfitting on train batch\n",
    "\n",
    "In this task you should check pipeline correctness by overfitting on you need to finetune Wav2Vec2 model and achieve 50 WER or lower accuracy on val set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f00dd9bc-8449-4ae2-924c-660a2217cd5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:15:34.451160Z",
     "iopub.status.busy": "2025-03-22T15:15:34.450289Z",
     "iopub.status.idle": "2025-03-22T15:15:34.486929Z",
     "shell.execute_reply": "2025-03-22T15:15:34.486248Z",
     "shell.execute_reply.started": "2025-03-22T15:15:34.451125Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "checkpointing_args = {\"use_reentrant\": False}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test\",\n",
    "    per_device_train_batch_size=2, # you could increase batch size\n",
    "    gradient_accumulation_steps=8, \n",
    "    evaluation_strategy=\"steps\",\n",
    "    max_steps=3000,\n",
    "    fp16=True,\n",
    "    save_steps=50,\n",
    "    eval_steps=10,\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4, \n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=300,\n",
    "    gradient_checkpointing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bda086b3-cee5-4fb8-ba20-190b845b92cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:15:34.710706Z",
     "iopub.status.busy": "2025-03-22T15:15:34.709941Z",
     "iopub.status.idle": "2025-03-22T15:15:34.720874Z",
     "shell.execute_reply": "2025-03-22T15:15:34.720301Z",
     "shell.execute_reply.started": "2025-03-22T15:15:34.710678Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1fe13fc-a8d0-40c2-adf2-c381b7103cae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:15:35.105307Z",
     "iopub.status.busy": "2025-03-22T15:15:35.104549Z",
     "iopub.status.idle": "2025-03-22T15:15:35.113064Z",
     "shell.execute_reply": "2025-03-22T15:15:35.112541Z",
     "shell.execute_reply.started": "2025-03-22T15:15:35.105278Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36ad6f56-50d2-4788-8d6c-c38a279a5597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:15:35.557369Z",
     "iopub.status.busy": "2025-03-22T15:15:35.556478Z",
     "iopub.status.idle": "2025-03-22T15:15:35.581500Z",
     "shell.execute_reply": "2025-03-22T15:15:35.580820Z",
     "shell.execute_reply.started": "2025-03-22T15:15:35.557334Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=CTCDataCollator(),\n",
    "    args=training_args,\n",
    "    compute_metrics=MetricsComputer(),\n",
    "    train_dataset=train,\n",
    "    eval_dataset=val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c362d922-6f53-4faf-820f-348674bb25a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T15:15:36.287952Z",
     "iopub.status.busy": "2025-03-22T15:15:36.287196Z",
     "iopub.status.idle": "2025-03-22T15:17:31.770157Z",
     "shell.execute_reply": "2025-03-22T15:17:31.768823Z",
     "shell.execute_reply.started": "2025-03-22T15:15:36.287927Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 67/3000 [30:59<22:36:41, 27.75s/it]\n",
      "\n",
      "  0%|          | 0/3000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/3000 [00:08<7:24:31,  8.89s/it]\u001b[A\n",
      "  0%|          | 2/3000 [00:13<5:24:59,  6.50s/it]\u001b[A\n",
      "  0%|          | 3/3000 [00:19<5:01:22,  6.03s/it]\u001b[A\n",
      "  0%|          | 4/3000 [00:25<5:06:58,  6.15s/it]\u001b[A\n",
      "  0%|          | 5/3000 [00:32<5:14:59,  6.31s/it]\u001b[A\n",
      "  0%|          | 6/3000 [00:37<5:06:38,  6.14s/it]\u001b[A\n",
      "  0%|          | 7/3000 [00:43<5:01:49,  6.05s/it]\u001b[A\n",
      "  0%|          | 8/3000 [00:48<4:35:43,  5.53s/it]\u001b[A\n",
      "  0%|          | 9/3000 [00:53<4:39:22,  5.60s/it]\u001b[A\n",
      "  0%|          | 10/3000 [01:00<4:59:11,  6.00s/it]\u001b[A\n",
      "                                                   \n",
      "  0%|          | 6/3000 [09:16<17:47:04, 21.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 100.8016, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 2/45 [00:01<00:41,  1.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 3/45 [00:03<00:52,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 4/45 [00:05<00:58,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 5/45 [00:06<00:56,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 6/45 [00:08<00:57,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 7/45 [00:10<01:02,  1.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 8/45 [00:12<01:03,  1.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 9/45 [00:14<01:04,  1.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 10/45 [00:16<01:06,  1.89s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 11/45 [00:18<01:04,  1.88s/it]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 12/45 [00:20<01:05,  1.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 13/45 [00:22<01:00,  1.90s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 14/45 [00:23<00:56,  1.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 15/45 [00:25<00:51,  1.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 16/45 [00:26<00:47,  1.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 17/45 [00:28<00:47,  1.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 18/45 [00:30<00:52,  1.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 19/45 [00:33<00:55,  2.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 20/45 [00:36<00:58,  2.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 21/45 [00:38<00:53,  2.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 22/45 [00:40<00:47,  2.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 23/45 [00:41<00:42,  1.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 24/45 [00:43<00:39,  1.89s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 25/45 [00:45<00:37,  1.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 26/45 [00:46<00:33,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 27/45 [00:48<00:29,  1.65s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 28/45 [00:49<00:28,  1.70s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.40 GiB. GPU 0 has a total capacity of 22.17 GiB of which 612.62 MiB is free. Including non-PyTorch memory, this process has 21.56 GiB memory in use. Of the allocated memory 14.80 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6517/4032920361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         )\n\u001b[0;32m-> 1539\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1540\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1899\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1901\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1902\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1903\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2224\u001b[0m                     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2226\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2934\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2935\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3122\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3123\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3124\u001b[0m             \u001b[0minputs_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_inputs_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3335\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mloss_without_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3336\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3337\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3338\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2679\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2680\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.11/site-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.11/site-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.11/site-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.11/site-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m         outputs = self.wav2vec2(\n\u001b[0m\u001b[1;32m   1964\u001b[0m             \u001b[0minput_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m         \u001b[0mextract_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m         \u001b[0mextract_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 )\n\u001b[1;32m    465\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2908\u001b[0m             \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2909\u001b[0m         )\n\u001b[0;32m-> 2910\u001b[0;31m     return torch.layer_norm(\n\u001b[0m\u001b[1;32m   2911\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m     )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 0 has a total capacity of 22.17 GiB of which 612.62 MiB is free. Including non-PyTorch memory, this process has 21.56 GiB memory in use. Of the allocated memory 14.80 GiB is allocated by PyTorch, and 6.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ad90d-7ccf-4fcf-ad8a-f4a2bef2a2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
